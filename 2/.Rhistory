plot(mickey, main = "Complete", col = nb, asp = T)
#Change hc_method to "ward" for the Ward.D2 distance.
hcut.res <- hcut(d, k = 3, hc_func = "hclust", hc_method = "complete", hc_metric = "euclidean")
fviz_silhouette(hcut.res, palette = "jco", ggtheme = theme_classic(), title = "PAM-Mickey")
# 3.
set.seed(123456)
mickey <- mickeyFunction(3000, 1000)
d <- dist(mickey, method = "euclidean")
hc.res <- hclust(d = d, method = "ward.D2")
plot(mickey, main = "Ward", col = cutree(hc.res, 3), asp = T)
# Exercise 2 - Valkompass ----
dat <- read.csv("http://ollion.cnrs.fr/wp-content/uploads/2023/05/Valkompass2014_ShortRecoded_anon.csv", encoding = "UTF-8")
#1.
#Access the variables about questions (start with Q)
active <- grep("^Q", colnames(dat), value = TRUE)
#Disjunctive table
datCluster <- ade4::acm.disjonctif(dat[, active])
#Full data with one-hot encoded questions
datCluster_full <- cbind(dat[, setdiff(colnames(dat), active)], datCluster)
#With k-means, 2 is the optimal number of clusters (with the silhouette method)
fviz_nbclust(datCluster, kmeans, method = "silhouette")
km.res <- kmeans(datCluster, 2, nstart = 10)
fviz_cluster(km.res, data = datCluster, ggtheme = theme_classic())
##PAM
fviz_nbclust(datCluster, pam, method = "silhouette")
pam.res <- pam(datCluster, 2)
fviz_cluster(pam.res, data = datCluster, ggtheme = theme_classic())
fviz_silhouette(pam.res, palette = "jco", ggtheme = theme_classic(), title = "PAM-SwedishMPs")
#With k-means, 2 is the optimal number of clusters (with the silhouette method)
fviz_nbclust(datCluster, kmeans, method = "silhouette")
fviz_silhouette(pam.res, palette = "jco", ggtheme = theme_classic(), title = "PAM-SwedishMPs")
#With k-means, 2 is the optimal number of clusters (with the silhouette method)
fviz_nbclust(datCluster, kmeans, method = "silhouette")
km.res <- kmeans(datCluster, 2, nstart = 10)
fviz_cluster(km.res, data = datCluster, ggtheme = theme_classic())
fviz_cluster(kmeans(datCluster, 3, nstart = 10),
data = datCluster, ggtheme = theme_classic())
fviz_cluster(kmeans(datCluster, 4, nstart = 10),
data = datCluster, ggtheme = theme_classic())
fviz_cluster(kmeans(datCluster, 6, nstart = 10),
data = datCluster, ggtheme = theme_classic())
fviz_cluster(kmeans(datCluster, 3, nstart = 10),
data = datCluster, ggtheme = theme_classic())
##PAM
fviz_nbclust(datCluster, pam, method = "silhouette")
pam.res <- pam(datCluster, 2)
fviz_cluster(pam.res, data = datCluster, ggtheme = theme_classic())
fviz_silhouette(pam.res, palette = "jco", ggtheme = theme_classic(), title = "PAM-SwedishMPs")
fviz_cluster(pam(datCluster, 3),
data = datCluster,
ggtheme = theme_classic())
fviz_silhouette(pam(datCluster, 3),
palette = "jco",
ggtheme = theme_classic(),
title = "PAM-SwedishMPs")
fviz_silhouette(pam.res, palette = "jco", ggtheme = theme_classic(), title = "PAM-SwedishMPs")
fviz_silhouette(pam(datCluster, 3),
palette = "jco",
ggtheme = theme_classic(),
title = "PAM-SwedishMPs")
fviz_cluster(pam(datCluster, 4),
data = datCluster,
ggtheme = theme_classic())
fviz_silhouette(pam(datCluster, 4),
palette = "jco",
ggtheme = theme_classic(),
title = "PAM-SwedishMPs")
fviz_cluster(pam(datCluster, 3),
data = datCluster,
ggtheme = theme_classic())
fviz_silhouette(pam(datCluster, 3),
palette = "jco",
ggtheme = theme_classic(),
title = "PAM-SwedishMPs")
fviz_cluster(pam.res, data = datCluster, ggtheme = theme_classic())
fviz_silhouette(pam.res, palette = "jco", ggtheme = theme_classic(), title = "PAM-SwedishMPs")
fviz_cluster(pam.res, data = datCluster, ggtheme = theme_classic())
fviz_cluster(pam(datCluster, 3),
data = datCluster,
ggtheme = theme_classic())
fviz_cluster(pam.res, data = datCluster, ggtheme = theme_classic())
##PAM
fviz_nbclust(datCluster, pam, method = "silhouette")
fviz_cluster(pam.res, data = datCluster, ggtheme = theme_classic())
fviz_cluster(kmeans(datCluster, 3, nstart = 10),
data = datCluster, ggtheme = theme_classic())
fviz_cluster(km.res, data = datCluster, ggtheme = theme_classic())
?fviz_cluster
##Hierarchical clustering
hc <- dist(datCluster, method = "euclidean") #Distance
res.hc <- hclust(hc, method = "ward.D2") #Linkage
fviz_nbclust(datCluster, hcut, hc_method = "ward.D2", method = c("silhouette"))
plot(res.hc, cex = 0.5, hang = -1)
rect.hclust(res.hc, k = 3)
#5. Look at the crosstable between individuals' political party and their
#cluster:
cluster <- cutree(res.hc, 2)
table(datCluster_full$PoliticalParty, cluster)
cluster <- cutree(res.hc, 5)
table(datCluster_full$PoliticalParty, cluster)
res.pca <- PCA(datCluster)
newDatCluster <- res.pca$ind$coord[, 1:2]
hc <- dist(newDatCluster, method = "euclidean") #Distance
res.hc <- hclust(hc, method = "ward.D2") #Linkage
plot(res.hc, cex = 0.5, hang = -1)
rect.hclust(res.hc, k = 3, border = 2:7)
fviz_nbclust(datCluster, hcut, hc_method = "ward.D2", method = c("silhouette"))
cluster <- cutree(res.hc, 3)
plot(newDatCluster[, 1:2], col = cluster)
# Data:
# Swedish Municipalities
df <- read.csv("http://ollion.cnrs.fr/wp-content/uploads/2019/05/ForeignBorninSwedenbyMunicipality2012.csv",encoding = "UTF-8")
rownames(df) <- df$Kommun
df <- df[, -c(1:2)]
df[is.na(df)] <- 0
df1 <- df[,-which(colnames(df) %in% c("Sweden", "Finland", "Norway"))]
df2 <- df1[-which(rownames(df1) %in% c("Malmö", "Göteborg", "Stockholm")),]
## Kmeans
km.res <- kmeans(df2, 2)
table(km.res$cluster)
fviz_cluster(km.res, data = df2, ggtheme=theme_classic())
##PAM
pam.res <- pam(df, 3)
table(pam.res$clustering)
fviz_cluster(pam.res, data = df, ggtheme=theme_classic())
fviz_silhouette(pam.res, palette = "jco",
ggtheme = theme_classic(), title="PAM-SwedishCities")
##Hierarchical clustering
hc <- dist(df, method = "euclidean")
res.hc <- hclust(hc, method = "ward.D2")
fviz_dend(res.hc, k = 3)
res.hc.nbclust <- NbClust(
data = df2,
distance = "euclidean",
min.nc = 2, # minimum number of clusters
max.nc = 5, # maximum number of clusters
method = "ward.D2" # one of: "ward.D", "ward.D2", "single", "complete", "average", "mcquitty", "median", "centroid", "kmeans"
)
shiny::runApp('~/Github/bibtex-analyzer')
shiny::runApp('~/Github/bibtex-analyzer')
library("ape")
library("Biostrings")
library("ggplot2")
library("ggtree")
nwk <- system.file("extdata", "sample.nwk", package="ggtree")
tree <- read.tree(nwk)
library("ape")
library("Biostrings")
install.packages("BiocManager")
library("ape")
library("Biostrings")
BiocManager::install("Biostrings")
library("ape")
library("Biostrings")
library("ggplot2")
library("ggtree")
BiocManager::install("ggtree")
library("ape")
library("Biostrings")
library("ggplot2")
library("ggtree")
library("ggtree")
install.packages("gtable")
library("ape")
library("Biostrings")
library("ggplot2")
library("ggtree")
nwk <- system.file("extdata", "sample.nwk", package="ggtree")
tree <- read.tree(nwk)
nwk <- system.file("extdata", "sample.nwk", package="treeio")
tree <- read.tree(nwk)
library("ggtree")
tree <- read.tree(nwk)
tree
View(tree)
ggtree(tree)
ggtree(tree, branch.length="none")
beast_file <- system.file("examples/MCC_FluA_H3.tree", package="ggtree")
beast_tree <- read.beast(beast_file)
library("ggtree")
beast_tree <- read.beast(beast_file)
beast_tree <- read.tree(beast_file)
ggtree(beast_tree, mrsd='2013-01-01') + theme_tree2() +
ggtitle("Divergence time")
ggtree(beast_tree, mrsd='2013-01-01') + theme_tree2() +
ggtitle("Divergence time")
beast_tree
ggtree(beast_tree[1], mrsd='2013-01-01') + theme_tree2() +
ggtitle("Divergence time")
ggtree(beast_tree[[1]], mrsd='2013-01-01') + theme_tree2() +
ggtitle("Divergence time")
View(beast_tree)
ggtree(beast_tree$`treeTREE1=`, mrsd='2013-01-01') + theme_tree2() +
ggtitle("Divergence time")
ggtree(beast_tree$`treeTREE1=`, mrsd='2013-01-01') + theme_tree2()
View(beast_tree)
ggtree(beast_tree$`treeTREE1=`, mrsd='2013-01-01')
ggtree(beast_tree$`treeTREE1=`, mrsd='2013-01-01') + theme_tree2()
beast_tree$`treeTREE1=`
beast_tree$`treeTREE1=` %>% head
install.packages("glmnet")
install.packages("mlbench")
install.packages("caret")
install.packages("splines2")
install.packages("ggeffects")
# Chunk 1
#| warning: false
#| echo: false
#| error: false
#| output: false
setwd("~/Github/ML-Labs/2")
set.seed(2)
library(data.table)
library(caret)
# Chunk 2
data <- fread("Kaggle_Social_Network_Ads.csv")[, `:=`(
user_id = NULL,
Purchased = as.factor(Purchased)
)]
# Chunk 3
tc <- caret::trainControl(method = "cv", number = 10)
model_knn <- caret::train(Purchased ~ .,
data = data,
preProcess = c("center","scale"),
tuneGrid = expand.grid(k = c(1:10,seq(15,25,5),50)),
method = "knn",
trControl = tc)
ggplot(model_knn$results, aes(x = k, y = Accuracy)) +
geom_line() +
geom_point() +
geom_vline(xintercept = model_knn$results$k[which.max(model_knn$results$Accuracy)],
color = "red") +
labs(title = "Accuracy of K-Nearest Neighbors model",
subtitle = "Trained with 10-fold cross-validation") +
scale_x_continuous(breaks = c(1:10,seq(15,25,5),50)) +
scale_y_continuous(breaks = seq(0.8,1,0.01)) +
theme_minimal()
# Chunk 4
data <- fread("Kaggle_Social_Network_Ads_Augmented.csv")[, `:=`(
user_id = NULL,
Purchased = as.factor(Purchased)
)]
# Chunk 5
tc <- caret::trainControl(method = "cv", number = 10)
model_knn <- caret::train(Purchased ~ .,
data = data,
preProcess = c("center","scale"),
tuneGrid = expand.grid(k = c(1:10,seq(15,25,5),50)),
method = "knn",
trControl = tc)
ggplot(model_knn$results, aes(x = k, y = Accuracy)) +
geom_line() +
geom_point() +
geom_vline(xintercept = model_knn$results$k[which.max(model_knn$results$Accuracy)],
color = "red") +
labs(title = "Accuracy of K-Nearest Neighbors model",
subtitle = "Trained with 10-fold cross-validation") +
scale_x_continuous(breaks = c(1:10,seq(15,25,5),50)) +
scale_y_continuous(breaks = seq(0,1,0.01)) +
theme_minimal()
c(0,0.01,0.025,0.05,0.10,0.25.0.5,1)
expand.grid(cp=c(0,0.01,0.025,0.05,0.10,0.25.0.5,1)
expand.grid(cp=c(0, 0.01, 0.025, 0.05, 0.10, 0.25, 0.5, 1)
)
model_tree <- caret::train(Purchased ~ .,
data = data,
tuneGrid = expand.grid(cp = c(0, 0.01, 0.025, 0.05,
0.10, 0.25, 0.5, 1)),
control = rpart.control(minbucket = 10),
method = "rpart",
trControl = tc)
warnings()
model_tree$results
model_tree <- caret::train(Purchased ~ .,
data = data,
tuneGrid = expand.grid(cp = c(0, 0.01, 0.025, 0.05,
0.10, 0.25, 0.5, 1)),
control = rpart.control(minbucket = 10),
method = "rpart",
trControl = tc)
model_tree <- caret::train(Purchased ~ .,
data = data,
tuneGrid = expand.grid(cp = c(0, 0.01, 0.025, 0.05,
0.10, 0.25, 0.5, 1)),
control = rpart.control(minbucket = 10),
method = "rpart",
trControl = tc)
warnings()
model_tree <- caret::train(Purchased ~ .,
data = data,
tuneGrid = expand.grid(cp = c(0, 0.01, 0.025, 0.05,
0.10, 0.25, 0.5, 1)),
control = rpart.control(minbucket = 10),
method = "rpart",
trControl = tc)
warnings()
#| warning: false
#| echo: false
#| error: false
#| output: false
setwd("~/Github/ML-Labs/2")
set.seed(2)
library(data.table)
library(caret)
library(rpart)
library(rpart.plot)
model_tree <- caret::train(Purchased ~ .,
data = data,
tuneGrid = expand.grid(cp = c(0, 0.01, 0.025, 0.05,
0.10, 0.25, 0.5, 1)),
control = rpart.control(minbucket = 10),
method = "rpart",
trControl = tc)
model_tree
model_tree$results
model_tree$results |> round(2)
model_tree$results |> round(3)
model_tree$results |> round(2)
model_tree$results |> round(3)
model_tree$results[,"cp"] |> round(3)
model_tree$results[,c("cp", "Accuracy")] |> round(3)
library(kableExtra)
model_tree$results[,c("cp", "Accuracy", "AccuracySD")] |> round(3) |> kable()
model_tree$results[,c("cp", "Accuracy", "AccuracySD")] |> round(3) |> plot()
model_tree$results[,c("cp", "Accuracy")] |> round(3) |> plot()
model_tree$results[,c("cp", "Accuracy")] |> round(3) |> plot(type = "l")
model_tree$results[,c("cp", "Accuracy")] |> round(3) |> plot(type = "l",
xlab = "Complexity Parameter Alpha",
main = "Decisiontree Accuracy")
model_tree$results[,c("cp", "Accuracy")] |> round(3) |> plot(type = "l",
xlab = "Complexity Parameter Alpha",
main = "Accuracy of Decision Tree")
model_tree$results[,c("cp", "Accuracy")] |> round(3) |> plot(type = "lp",
xlab = "Complexity Parameter Alpha",
main = "Accuracy of Decision Tree")
?plot
model_tree$results[,c("cp", "Accuracy")] |> round(3) |> plot(type = "b",
xlab = "Complexity Parameter Alpha",
main = "Accuracy of Decision Tree")
model_tree$results[,c("cp", "Accuracy")] |>
round(3) |>
plot(type = "b",
xlab = "Complexity Parameter Alpha",
main = "Accuracy of Decision Tree") |>
vline(0.2)
max(model_tree$results$Accuracy)
model_tree$results[,c("cp", "Accuracy")] |>
round(3) |>
plot(type = "b",
xlab = "Complexity Parameter Alpha",
main = "Accuracy of Decision Tree") +
abline(h = max(model_tree$results$Accuracy), col = "red", lty = 2)
model_tree$results[,c("cp", "Accuracy")] |>
round(3) |>
plot(type = "b",
xlab = "Complexity Parameter Alpha",
main = "Accuracy of Decision Tree") +
abline(v = max(model_tree$resultscp[which.max(model_tree$results$Accuracy)]), col = "red", lty = 2)
model_tree$resultscp[which.max(model_tree$results$Accuracy)]
model_tree$results$Accuracy
which.max(model_tree$results$Accuracy)
model_tree$resultscp
model_tree$results$cp
model_tree$results[,c("cp", "Accuracy")] |>
round(3) |>
plot(type = "b",
xlab = "Complexity Parameter Alpha",
main = "Accuracy of Decision Tree") +
abline(v = model_tree$results$cp[which.max(model_tree$results$Accuracy)], col = "red", lty = 2)
?plot
model_tree$results[,c("cp", "Accuracy")] |>
round(3) |>
plot(type = "b", bty = "n", xaxt = "n", yaxt = "n",
xlab = "Complexity Parameter Alpha",
main = "Accuracy of Decision Tree") +
abline(v = model_tree$results$cp[which.max(model_tree$results$Accuracy)], col = "red", lty = 2)
model_tree$results[,c("cp", "Accuracy")] |>
round(3) |>
plot(type = "b", bty = "n",
xlab = "Complexity Parameter Alpha",
main = "Accuracy of Decision Tree") +
abline(v = model_tree$results$cp[which.max(model_tree$results$Accuracy)], col = "red", lty = 2)
?bty
model_tree$results[,c("cp", "Accuracy")] |>
round(3) |>
plot(type = "b", bty = "n",
xlab = "Complexity Parameter Alpha",
main = "Accuracy of Decision Tree") +
abline(v = model_tree$results$cp[which.max(model_tree$results$Accuracy)], col = "red", lty = 2) +
box("plot",
## Add 'box' lines to the bottom and left of the plot.
bty = "l",
## Increase width of box lines.
lwd = 2)
model_tree$results[,c("cp", "Accuracy")] |>
round(3) |>
plot(type = "b", bty = "n", pch = 20
xlab = "Complexity Parameter Alpha",
model_tree$results[,c("cp", "Accuracy")] |>
round(3) |>
plot(type = "b", bty = "n", pch = 20
xlab = "Complexity Parameter Alpha",
model_tree$results[,c("cp", "Accuracy")] |>
round(3) |>
plot(type = "b", bty = "n", pch = 20
xlab = "Complexity Parameter Alpha",
model_tree$results[,c("cp", "Accuracy")] |>
round(3) |>
plot(type = "b", bty = "n", pch = 20,
xlab = "Complexity Parameter Alpha",
main = "Accuracy of Decision Tree") +
box("plot", bty = "l", lwd = 2) +
abline(v = model_tree$results$cp[which.max(model_tree$results$Accuracy)], col = "red", lty = 2)
model_tree$results[,c("cp", "Accuracy")] |>
round(3) |>
plot(type = "b", bty = "n", pch = 20, cex = 1.4,
xlab = "Complexity Parameter Alpha",
main = "Accuracy of Decision Tree") +
box("plot", bty = "l", lwd = 2) +
abline(v = model_tree$results$cp[which.max(model_tree$results$Accuracy)], col = "red", lty = 2)
model_tree$results[,c("cp", "Accuracy")] |>
round(3) |>
plot(type = "b", bty = "n",
xlab = "Complexity Parameter Alpha",
main = "Accuracy of Decision Tree") +
box("plot", bty = "l", lwd = 2) +
abline(v = model_tree$results$cp[which.max(model_tree$results$Accuracy)], col = "red", lty = 2)
model_tree$results[,c("cp", "Accuracy")] |>
round(3) |>
plot(type = "b", bty = "n", pch = 20, cex = 1.4, las = 1
xlab = "Complexity Parameter Alpha",
model_tree$results[,c("cp", "Accuracy")] |>
round(3) |>
plot(type = "b", bty = "n", pch = 20, cex = 1.4, las = 1,
xlab = "Complexity Parameter Alpha",
main = "Accuracy of Decision Tree") +
box("plot", bty = "l", lwd = 2) +
abline(v = model_tree$results$cp[which.max(model_tree$results$Accuracy)], col = "red", lty = 2)
model_tree$results[,c("cp", "Accuracy")] |>
round(3) |>
plot(type = "b", bty = "n", pch = 20, cex = 1.6, las = 1,
xlab = "Complexity Parameter Alpha",
main = "Accuracy of Decision Tree") +
box("plot", bty = "l", lwd = 2) +
abline(v = model_tree$results$cp[which.max(model_tree$results$Accuracy)], col = "red", lty = 2)
model_tree$results[,c("cp", "Accuracy")] |>
round(3) |>
plot(type = "b", bty = "n", pch = 20, cex = 2, las = 1,
xlab = "Complexity Parameter Alpha",
main = "Accuracy of Decision Tree") +
box("plot", bty = "l", lwd = 2) +
abline(v = model_tree$results$cp[which.max(model_tree$results$Accuracy)], col = "red", lty = 2)
model_tree$results[,c("cp", "Accuracy")] |>
round(3) |>
plot(type = "b", bty = "n", pch = 20, cex = 1.5, las = 1,
xlab = "Complexity Parameter Alpha",
main = "Accuracy of Decision Tree") +
box("plot", bty = "l", lwd = 2) +
abline(v = model_tree$results$cp[which.max(model_tree$results$Accuracy)], col = "red", lty = 2)
model_tree$results[,c("cp", "Accuracy")] |>
round(3) |>
plot(type = "b", bty = "n", pch = 20, cex = 1.5, las = 1,
xlab = "Complexity Parameter Alpha",
main = "Accuracy of Decision Tree")
box("plot", bty = "l", lwd = 2)
abline(v = model_tree$results$cp[which.max(model_tree$results$Accuracy)], col = "red", lty = 2)
model_tree$results[,c("cp", "Accuracy")] |>
round(3) |>
plot(type = "b", bty = "n", pch = 20, cex = 1.5, las = 1,
xlab = "Complexity Parameter Alpha",
main = "Accuracy of Decision Tree")
box("plot", bty = "l", lwd = 2)
abline(v = model_tree$results$cp[which.max(model_tree$results$Accuracy)], col = "red", lty = 2)
model_tree$results[,c("cp", "Accuracy")] |>
round(3) |>
plot(type = "b", bty = "n", pch = 20, cex = 1.5, las = 1,
xlab = "Complexity Parameter Alpha",
main = "Accuracy of Decision Tree")
box("plot", bty = "l", lwd = 2)
abline(v = model_tree$results$cp[which.max(model_tree$results$Accuracy)], col = "red", lty = 2)
model_tree$results[,c("cp", "Accuracy")] |>
round(3) |>
plot(type = "b", bty = "n", pch = 20, cex = 1.5, las = 1,
xlab = "Complexity Parameter Alpha",
main = "Accuracy of Decision Tree")
box("plot", bty = "l", lwd = 2)
abline(v = model_tree$results$cp[which.max(model_tree$results$Accuracy)], col = "red", lty = 2)
dev.off()
rpart.plot(model_tree$finalModel)
model_tree$results$Accuracy |> max()
model_tree$results$Accuracy |> max() |> round()
model_tree$results$Accuracy |> max() |> round(2)
tc <- caret::trainControl(method = "cv", number = 10)
model_knn <- caret::train(Purchased ~ .,
data = data,
preProcess = c("center","scale"),
tuneGrid = expand.grid(k = c(1:10,seq(15,25,5),50)),
method = "knn",
trControl = tc)
ggplot(model_knn$results, aes(x = k, y = Accuracy)) +
geom_line() +
geom_point() +
geom_vline(xintercept = model_knn$results$k[which.max(model_knn$results$Accuracy)],
color = "red") +
labs(title = "Accuracy of K-Nearest Neighbors model",
subtitle = "Trained with 10-fold cross-validation") +
scale_x_continuous(breaks = c(1:10,seq(15,25,5),50)) +
scale_y_continuous(breaks = seq(0,1,0.01)) +
theme_minimal()
rpart.plot(model_tree$finalModel)
caret::varImp(model_tree$finalModel)
caret::varImp(model_tree$finalModel) |> sort()
